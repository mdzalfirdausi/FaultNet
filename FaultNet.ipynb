{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path('.')\n",
    "DATA_PATH = Path(\"./Data/Paderborn files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Firdaus\\\\Belajar\\\\Paderborn'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.load(DATA_PATH/'raw_signal_data.npy')\n",
    "labels = np.load(DATA_PATH/'raw_signal_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[:,0:1600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(data,no_elements):\n",
    "    X=np.zeros((data.shape[0],data.shape[1]))\n",
    "    for i in range(data.shape[1]-no_elements+1):\n",
    "        X[:,i]=np.mean(data[:,i:i+no_elements],axis=1)\n",
    "    return X.astype(np.float16)\n",
    "def median(data,no_elements):\n",
    "    X=np.zeros((data.shape[0],data.shape[1]))\n",
    "    for i in range(data.shape[1]-no_elements+1):\n",
    "        X[:,i]=np.median(data[:,i:i+no_elements],axis=1)\n",
    "    return X.astype(np.float16)\n",
    "def sig_image(data,size):\n",
    "    X=np.zeros((data.shape[0],size,size))\n",
    "    for i in range(data.shape[0]):\n",
    "        X[i]=(data[i,:].reshape(size,size))\n",
    "    return X.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "channel_mean=(mean(x,10)).astype(np.float16)\n",
    "x_m=sig_image(channel_mean,40)\n",
    "channel_median=(median(x,10)).astype(np.float16)\n",
    "x_md=sig_image(x,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n=sig_image(x,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58000, 40, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58000, 40, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.stack((x_n,x_m,x_md),axis=1).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58000, 3, 40, 40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainx, testx, trainlabel, testlabel = train_test_split(X, labels, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_train, sig_test = trainx,testx\n",
    "lab_train, lab_test = trainlabel,testlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_train = torch.from_numpy(sig_train)\n",
    "sig_test = torch.from_numpy(sig_test)\n",
    "lab_train= torch.from_numpy(lab_train)\n",
    "lab_test = torch.from_numpy(lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46400, 3, 40, 40])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "batch_size = 128 \n",
    "train_tensor = data_utils.TensorDataset(sig_train, lab_train) \n",
    "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "test_tensor = data_utils.TensorDataset(sig_test, lab_test) \n",
    "test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46400, 3, 40, 40])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11600, 3, 40, 40])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=4,stride=1,padding = 1)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=4,stride=2)\n",
    "        self.conv2 = nn.Conv2d(32,64, kernel_size=4,stride =1)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=4,stride=2)\n",
    "        self.fc1= nn.Linear(2304,256)\n",
    "        self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp1(self.conv1(x)))\n",
    "        x = F.relu(self.mp2(self.conv2(x)))\n",
    "        x = x.view(in_size,-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/363], Loss: 2.3245, Train Accuracy: 0.78%\n",
      "Epoch [1/5], Step [2/363], Loss: 1.8126, Train Accuracy: 42.19%\n",
      "Epoch [1/5], Step [3/363], Loss: 1.3959, Train Accuracy: 35.16%\n",
      "Epoch [1/5], Step [4/363], Loss: 1.1324, Train Accuracy: 41.41%\n",
      "Epoch [1/5], Step [5/363], Loss: 1.3164, Train Accuracy: 37.50%\n",
      "Epoch [1/5], Step [6/363], Loss: 1.1250, Train Accuracy: 37.50%\n",
      "Epoch [1/5], Step [7/363], Loss: 1.3880, Train Accuracy: 33.59%\n",
      "Epoch [1/5], Step [8/363], Loss: 1.3750, Train Accuracy: 29.69%\n",
      "Epoch [1/5], Step [9/363], Loss: 1.1103, Train Accuracy: 40.62%\n",
      "Epoch [1/5], Step [10/363], Loss: 1.2737, Train Accuracy: 42.19%\n",
      "Epoch [1/5], Step [11/363], Loss: 1.2393, Train Accuracy: 39.06%\n",
      "Epoch [1/5], Step [12/363], Loss: 1.1529, Train Accuracy: 46.09%\n",
      "Epoch [1/5], Step [13/363], Loss: 1.1363, Train Accuracy: 41.41%\n",
      "Epoch [1/5], Step [14/363], Loss: 1.1152, Train Accuracy: 32.03%\n",
      "Epoch [1/5], Step [15/363], Loss: 1.0959, Train Accuracy: 39.84%\n",
      "Epoch [1/5], Step [16/363], Loss: 1.1477, Train Accuracy: 39.84%\n",
      "Epoch [1/5], Step [17/363], Loss: 1.1723, Train Accuracy: 32.03%\n",
      "Epoch [1/5], Step [18/363], Loss: 1.1321, Train Accuracy: 39.06%\n",
      "Epoch [1/5], Step [19/363], Loss: 1.1068, Train Accuracy: 45.31%\n",
      "Epoch [1/5], Step [20/363], Loss: 1.0681, Train Accuracy: 35.94%\n",
      "Epoch [1/5], Step [21/363], Loss: 1.0709, Train Accuracy: 41.41%\n",
      "Epoch [1/5], Step [22/363], Loss: 1.0187, Train Accuracy: 41.41%\n",
      "Epoch [1/5], Step [23/363], Loss: 1.0828, Train Accuracy: 40.62%\n",
      "Epoch [1/5], Step [24/363], Loss: 1.0429, Train Accuracy: 37.50%\n",
      "Epoch [1/5], Step [25/363], Loss: 1.1304, Train Accuracy: 37.50%\n",
      "Epoch [1/5], Step [26/363], Loss: 1.0185, Train Accuracy: 42.97%\n",
      "Epoch [1/5], Step [27/363], Loss: 1.0456, Train Accuracy: 41.41%\n",
      "Epoch [1/5], Step [28/363], Loss: 1.0095, Train Accuracy: 42.19%\n",
      "Epoch [1/5], Step [29/363], Loss: 1.0382, Train Accuracy: 37.50%\n",
      "Epoch [1/5], Step [30/363], Loss: 0.9949, Train Accuracy: 42.97%\n",
      "Epoch [1/5], Step [31/363], Loss: 0.9861, Train Accuracy: 44.53%\n",
      "Epoch [1/5], Step [32/363], Loss: 1.0674, Train Accuracy: 42.19%\n",
      "Epoch [1/5], Step [33/363], Loss: 0.9905, Train Accuracy: 42.97%\n",
      "Epoch [1/5], Step [34/363], Loss: 0.9528, Train Accuracy: 51.56%\n",
      "Epoch [1/5], Step [35/363], Loss: 0.9863, Train Accuracy: 44.53%\n",
      "Epoch [1/5], Step [36/363], Loss: 0.9898, Train Accuracy: 52.34%\n",
      "Epoch [1/5], Step [37/363], Loss: 1.0181, Train Accuracy: 47.66%\n",
      "Epoch [1/5], Step [38/363], Loss: 0.9536, Train Accuracy: 50.00%\n",
      "Epoch [1/5], Step [39/363], Loss: 0.8986, Train Accuracy: 55.47%\n",
      "Epoch [1/5], Step [40/363], Loss: 0.9321, Train Accuracy: 50.78%\n",
      "Epoch [1/5], Step [41/363], Loss: 0.9683, Train Accuracy: 45.31%\n",
      "Epoch [1/5], Step [42/363], Loss: 0.9540, Train Accuracy: 41.41%\n",
      "Epoch [1/5], Step [43/363], Loss: 0.8896, Train Accuracy: 49.22%\n",
      "Epoch [1/5], Step [44/363], Loss: 0.8476, Train Accuracy: 57.03%\n",
      "Epoch [1/5], Step [45/363], Loss: 0.8980, Train Accuracy: 50.00%\n",
      "Epoch [1/5], Step [46/363], Loss: 0.8971, Train Accuracy: 53.12%\n",
      "Epoch [1/5], Step [47/363], Loss: 0.8536, Train Accuracy: 57.03%\n",
      "Epoch [1/5], Step [48/363], Loss: 0.8277, Train Accuracy: 52.34%\n",
      "Epoch [1/5], Step [49/363], Loss: 0.9114, Train Accuracy: 54.69%\n",
      "Epoch [1/5], Step [50/363], Loss: 0.8744, Train Accuracy: 59.38%\n",
      "Epoch [1/5], Step [51/363], Loss: 0.8644, Train Accuracy: 57.03%\n",
      "Epoch [1/5], Step [52/363], Loss: 0.8937, Train Accuracy: 54.69%\n",
      "Epoch [1/5], Step [53/363], Loss: 0.8329, Train Accuracy: 50.78%\n",
      "Epoch [1/5], Step [54/363], Loss: 0.7841, Train Accuracy: 60.16%\n",
      "Epoch [1/5], Step [55/363], Loss: 0.7942, Train Accuracy: 60.94%\n",
      "Epoch [1/5], Step [56/363], Loss: 0.7545, Train Accuracy: 59.38%\n",
      "Epoch [1/5], Step [57/363], Loss: 0.8643, Train Accuracy: 53.91%\n",
      "Epoch [1/5], Step [58/363], Loss: 0.8913, Train Accuracy: 56.25%\n",
      "Epoch [1/5], Step [59/363], Loss: 0.8176, Train Accuracy: 55.47%\n",
      "Epoch [1/5], Step [60/363], Loss: 0.9029, Train Accuracy: 44.53%\n",
      "Epoch [1/5], Step [61/363], Loss: 0.8514, Train Accuracy: 46.09%\n",
      "Epoch [1/5], Step [62/363], Loss: 0.8031, Train Accuracy: 53.12%\n",
      "Epoch [1/5], Step [63/363], Loss: 0.8195, Train Accuracy: 53.12%\n",
      "Epoch [1/5], Step [64/363], Loss: 0.8268, Train Accuracy: 61.72%\n",
      "Epoch [1/5], Step [65/363], Loss: 0.8045, Train Accuracy: 57.03%\n",
      "Epoch [1/5], Step [66/363], Loss: 0.7127, Train Accuracy: 69.53%\n",
      "Epoch [1/5], Step [67/363], Loss: 0.6987, Train Accuracy: 65.62%\n",
      "Epoch [1/5], Step [68/363], Loss: 0.7331, Train Accuracy: 64.84%\n",
      "Epoch [1/5], Step [69/363], Loss: 0.7524, Train Accuracy: 53.12%\n",
      "Epoch [1/5], Step [70/363], Loss: 0.7496, Train Accuracy: 56.25%\n",
      "Epoch [1/5], Step [71/363], Loss: 0.8157, Train Accuracy: 52.34%\n",
      "Epoch [1/5], Step [72/363], Loss: 0.7492, Train Accuracy: 60.16%\n",
      "Epoch [1/5], Step [73/363], Loss: 0.7595, Train Accuracy: 62.50%\n",
      "Epoch [1/5], Step [74/363], Loss: 0.7761, Train Accuracy: 60.94%\n",
      "Epoch [1/5], Step [75/363], Loss: 0.7617, Train Accuracy: 61.72%\n",
      "Epoch [1/5], Step [76/363], Loss: 0.6913, Train Accuracy: 69.53%\n",
      "Epoch [1/5], Step [77/363], Loss: 0.7199, Train Accuracy: 65.62%\n",
      "Epoch [1/5], Step [78/363], Loss: 0.6882, Train Accuracy: 67.19%\n",
      "Epoch [1/5], Step [79/363], Loss: 0.7036, Train Accuracy: 65.62%\n",
      "Epoch [1/5], Step [80/363], Loss: 0.7046, Train Accuracy: 65.62%\n",
      "Epoch [1/5], Step [81/363], Loss: 0.7096, Train Accuracy: 67.97%\n",
      "Epoch [1/5], Step [82/363], Loss: 0.7846, Train Accuracy: 57.03%\n",
      "Epoch [1/5], Step [83/363], Loss: 0.6265, Train Accuracy: 77.34%\n",
      "Epoch [1/5], Step [84/363], Loss: 0.7054, Train Accuracy: 63.28%\n",
      "Epoch [1/5], Step [85/363], Loss: 0.7303, Train Accuracy: 60.94%\n",
      "Epoch [1/5], Step [86/363], Loss: 0.7064, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [87/363], Loss: 0.6336, Train Accuracy: 69.53%\n",
      "Epoch [1/5], Step [88/363], Loss: 0.6826, Train Accuracy: 74.22%\n",
      "Epoch [1/5], Step [89/363], Loss: 0.6476, Train Accuracy: 71.09%\n",
      "Epoch [1/5], Step [90/363], Loss: 0.7991, Train Accuracy: 67.19%\n",
      "Epoch [1/5], Step [91/363], Loss: 0.6794, Train Accuracy: 64.06%\n",
      "Epoch [1/5], Step [92/363], Loss: 0.7151, Train Accuracy: 65.62%\n",
      "Epoch [1/5], Step [93/363], Loss: 0.6855, Train Accuracy: 67.97%\n",
      "Epoch [1/5], Step [94/363], Loss: 0.7169, Train Accuracy: 62.50%\n",
      "Epoch [1/5], Step [95/363], Loss: 0.7056, Train Accuracy: 60.94%\n",
      "Epoch [1/5], Step [96/363], Loss: 0.7573, Train Accuracy: 61.72%\n",
      "Epoch [1/5], Step [97/363], Loss: 0.7162, Train Accuracy: 63.28%\n",
      "Epoch [1/5], Step [98/363], Loss: 0.7734, Train Accuracy: 65.62%\n",
      "Epoch [1/5], Step [99/363], Loss: 0.6795, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [100/363], Loss: 0.6805, Train Accuracy: 66.41%\n",
      "Epoch [1/5], Step [101/363], Loss: 0.6181, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [102/363], Loss: 0.6281, Train Accuracy: 69.53%\n",
      "Epoch [1/5], Step [103/363], Loss: 0.6290, Train Accuracy: 71.09%\n",
      "Epoch [1/5], Step [104/363], Loss: 0.6295, Train Accuracy: 71.88%\n",
      "Epoch [1/5], Step [105/363], Loss: 0.6094, Train Accuracy: 74.22%\n",
      "Epoch [1/5], Step [106/363], Loss: 0.6218, Train Accuracy: 67.97%\n",
      "Epoch [1/5], Step [107/363], Loss: 0.6140, Train Accuracy: 71.09%\n",
      "Epoch [1/5], Step [108/363], Loss: 0.5473, Train Accuracy: 82.03%\n",
      "Epoch [1/5], Step [109/363], Loss: 0.6164, Train Accuracy: 71.09%\n",
      "Epoch [1/5], Step [110/363], Loss: 0.6363, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [111/363], Loss: 0.5631, Train Accuracy: 71.88%\n",
      "Epoch [1/5], Step [112/363], Loss: 0.6734, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [113/363], Loss: 0.7165, Train Accuracy: 62.50%\n",
      "Epoch [1/5], Step [114/363], Loss: 0.5888, Train Accuracy: 69.53%\n",
      "Epoch [1/5], Step [115/363], Loss: 0.6560, Train Accuracy: 67.19%\n",
      "Epoch [1/5], Step [116/363], Loss: 0.6095, Train Accuracy: 65.62%\n",
      "Epoch [1/5], Step [117/363], Loss: 0.6605, Train Accuracy: 67.19%\n",
      "Epoch [1/5], Step [118/363], Loss: 0.6347, Train Accuracy: 66.41%\n",
      "Epoch [1/5], Step [119/363], Loss: 0.6516, Train Accuracy: 71.09%\n",
      "Epoch [1/5], Step [120/363], Loss: 0.5882, Train Accuracy: 69.53%\n",
      "Epoch [1/5], Step [121/363], Loss: 0.6287, Train Accuracy: 70.31%\n",
      "Epoch [1/5], Step [122/363], Loss: 0.5531, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [123/363], Loss: 0.6217, Train Accuracy: 71.09%\n",
      "Epoch [1/5], Step [124/363], Loss: 0.5354, Train Accuracy: 77.34%\n",
      "Epoch [1/5], Step [125/363], Loss: 0.5539, Train Accuracy: 75.78%\n",
      "Epoch [1/5], Step [126/363], Loss: 0.5944, Train Accuracy: 66.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [127/363], Loss: 0.5379, Train Accuracy: 75.00%\n",
      "Epoch [1/5], Step [128/363], Loss: 0.5953, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [129/363], Loss: 0.6084, Train Accuracy: 65.62%\n",
      "Epoch [1/5], Step [130/363], Loss: 0.5287, Train Accuracy: 76.56%\n",
      "Epoch [1/5], Step [131/363], Loss: 0.5767, Train Accuracy: 74.22%\n",
      "Epoch [1/5], Step [132/363], Loss: 0.4591, Train Accuracy: 78.12%\n",
      "Epoch [1/5], Step [133/363], Loss: 0.5753, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [134/363], Loss: 0.5433, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [135/363], Loss: 0.5147, Train Accuracy: 78.12%\n",
      "Epoch [1/5], Step [136/363], Loss: 0.5949, Train Accuracy: 71.09%\n",
      "Epoch [1/5], Step [137/363], Loss: 0.5594, Train Accuracy: 75.78%\n",
      "Epoch [1/5], Step [138/363], Loss: 0.5092, Train Accuracy: 79.69%\n",
      "Epoch [1/5], Step [139/363], Loss: 0.5499, Train Accuracy: 75.78%\n",
      "Epoch [1/5], Step [140/363], Loss: 0.5743, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [141/363], Loss: 0.5602, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [142/363], Loss: 0.5063, Train Accuracy: 79.69%\n",
      "Epoch [1/5], Step [143/363], Loss: 0.5847, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [144/363], Loss: 0.6191, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [145/363], Loss: 0.5090, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [146/363], Loss: 0.5985, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [147/363], Loss: 0.5150, Train Accuracy: 78.91%\n",
      "Epoch [1/5], Step [148/363], Loss: 0.5900, Train Accuracy: 71.88%\n",
      "Epoch [1/5], Step [149/363], Loss: 0.5224, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [150/363], Loss: 0.4261, Train Accuracy: 82.81%\n",
      "Epoch [1/5], Step [151/363], Loss: 0.5217, Train Accuracy: 76.56%\n",
      "Epoch [1/5], Step [152/363], Loss: 0.5738, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [153/363], Loss: 0.5527, Train Accuracy: 74.22%\n",
      "Epoch [1/5], Step [154/363], Loss: 0.6083, Train Accuracy: 71.88%\n",
      "Epoch [1/5], Step [155/363], Loss: 0.5252, Train Accuracy: 75.78%\n",
      "Epoch [1/5], Step [156/363], Loss: 0.5878, Train Accuracy: 70.31%\n",
      "Epoch [1/5], Step [157/363], Loss: 0.5325, Train Accuracy: 71.88%\n",
      "Epoch [1/5], Step [158/363], Loss: 0.5820, Train Accuracy: 67.19%\n",
      "Epoch [1/5], Step [159/363], Loss: 0.5757, Train Accuracy: 78.12%\n",
      "Epoch [1/5], Step [160/363], Loss: 0.4819, Train Accuracy: 76.56%\n",
      "Epoch [1/5], Step [161/363], Loss: 0.4801, Train Accuracy: 81.25%\n",
      "Epoch [1/5], Step [162/363], Loss: 0.6533, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [163/363], Loss: 0.5689, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [164/363], Loss: 0.5407, Train Accuracy: 75.00%\n",
      "Epoch [1/5], Step [165/363], Loss: 0.4882, Train Accuracy: 76.56%\n",
      "Epoch [1/5], Step [166/363], Loss: 0.6564, Train Accuracy: 67.97%\n",
      "Epoch [1/5], Step [167/363], Loss: 0.5810, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [168/363], Loss: 0.5052, Train Accuracy: 77.34%\n",
      "Epoch [1/5], Step [169/363], Loss: 0.5514, Train Accuracy: 75.00%\n",
      "Epoch [1/5], Step [170/363], Loss: 0.5168, Train Accuracy: 77.34%\n",
      "Epoch [1/5], Step [171/363], Loss: 0.6191, Train Accuracy: 67.97%\n",
      "Epoch [1/5], Step [172/363], Loss: 0.5361, Train Accuracy: 76.56%\n",
      "Epoch [1/5], Step [173/363], Loss: 0.6327, Train Accuracy: 74.22%\n",
      "Epoch [1/5], Step [174/363], Loss: 0.6379, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [175/363], Loss: 0.6181, Train Accuracy: 71.88%\n",
      "Epoch [1/5], Step [176/363], Loss: 0.4594, Train Accuracy: 81.25%\n",
      "Epoch [1/5], Step [177/363], Loss: 0.5920, Train Accuracy: 73.44%\n",
      "Epoch [1/5], Step [178/363], Loss: 0.5338, Train Accuracy: 74.22%\n",
      "Epoch [1/5], Step [179/363], Loss: 0.5917, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [180/363], Loss: 0.5677, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [181/363], Loss: 0.7113, Train Accuracy: 64.06%\n",
      "Epoch [1/5], Step [182/363], Loss: 0.5926, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [183/363], Loss: 0.5035, Train Accuracy: 80.47%\n",
      "Epoch [1/5], Step [184/363], Loss: 0.5214, Train Accuracy: 74.22%\n",
      "Epoch [1/5], Step [185/363], Loss: 0.4593, Train Accuracy: 82.03%\n",
      "Epoch [1/5], Step [186/363], Loss: 0.5885, Train Accuracy: 68.75%\n",
      "Epoch [1/5], Step [187/363], Loss: 0.5267, Train Accuracy: 72.66%\n",
      "Epoch [1/5], Step [188/363], Loss: 0.5351, Train Accuracy: 74.22%\n",
      "Epoch [1/5], Step [189/363], Loss: 0.4228, Train Accuracy: 81.25%\n",
      "Epoch [1/5], Step [190/363], Loss: 0.4942, Train Accuracy: 79.69%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-722c5e53fb16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msignals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-561a329b4db7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0min_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmp1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmp2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    153\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m    154\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                             self.return_indices)\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     return torch.max_pool2d(\n\u001b[1;32m--> 586\u001b[1;33m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Run the forward pass\n",
    "        signals=signals\n",
    "        labels=labels\n",
    "        outputs = cnn(signals.double())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels.long()).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (epoch+1) % 5 == 0 or epoch==0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Train Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(test_loader)\n",
    "print(total_step)\n",
    "loss_list_test = []\n",
    "acc_list_test = []\n",
    "with torch.no_grad():\n",
    "    for i, (signals, labels) in enumerate(test_loader):\n",
    "        # Run the forward pass\n",
    "        signals=signals\n",
    "        labels=labels\n",
    "        outputs = cnn(signals.double())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss_list_test.append(loss.item())\n",
    "        if epoch%10 ==0:\n",
    "            print(loss)\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels.long()).sum().item()\n",
    "        acc_list_test.append(correct / total)\n",
    "        if (epoch) % 1 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# if you need to save\n",
    "torch.save(cnn,'cnnTC3_fold3_45.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
